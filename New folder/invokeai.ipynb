{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Installing InvokeAI - Required","metadata":{}},{"cell_type":"code","source":"import os\nimport subprocess\n\nenv = os.environ.copy()\n\n!pip install pillow==9.5.0 requests==2.31.0 xformers==0.0.20 triton==2.0.0\n!pip install git+https://github.com/openai/CLIP.git@main#egg=clip\n!pip install git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n!pip install git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n!pip install git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n!pip install 'InvokeAI[xformers]==3.6.0' --use-pep517 --extra-index-url https://download.pytorch.org/whl/cu118\n!pip install --force-reinstall numpy\n\n!mamba install openssh -y \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \n### Configuration and downloading default models - Required","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:19:08.106554Z","iopub.execute_input":"2024-04-08T07:19:08.106959Z","iopub.status.idle":"2024-04-08T07:19:23.905268Z","shell.execute_reply.started":"2024-04-08T07:19:08.106924Z","shell.execute_reply":"2024-04-08T07:19:23.904291Z"}}},{"cell_type":"code","source":"!mkdir /kaggle/temp/\n!mkdir /kaggle/temp/invokeai\n!mkdir /kaggle/temp/invokeai/configs\n\n#@markdown Download only the default model in initial configuration.\n#@markdown Checking this prevents running out of space in Colab.\n\ndefaultOnly = True #@param {type:\"boolean\"}\nskipWeights = True #@param {type:\"boolean\"}\nskipSupportModels = False #@param {type:\"boolean\"}\nnoFullPrecision = True\n\n#@markdown This step usually takes about 2 minutes with only the default model and no weights.\n\n#@markdown You can ignore \"File exists\" warnings in the output.\n\ncmd = 'invokeai-configure --root_dir /kaggle/temp/invokeai --yes'\n\nif defaultOnly:\n  cmd += ' --default_only'\n\nif skipWeights:\n  cmd += ' --skip-sd-weights'\n\nif skipSupportModels:\n  cmd += ' --skip-support-models'\n\nsubprocess.run(cmd, shell=True, env=env)\n\nimport fileinput\nimport os\ndef find(name, path):\n    for root, dirs, files in os.walk(path):\n        if name in files:\n            return os.path.join(root, name)\n\nif noFullPrecision:\n  model_install_file = find('model_install_backend.py', '/opt/conda/lib/')\n  print('modifying file ' + str(model_install_file))\n  for line in fileinput.input(model_install_file, inplace=True):\n    if ('precision = torch_dtype(choose_torch_device())' in line):\n       line = line.replace('torch_dtype(choose_torch_device())', 'torch.float16')\n    print(line, end='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Add the Dreamshaper SDXL model (optional)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T07:21:33.763307Z","iopub.execute_input":"2024-04-08T07:21:33.763647Z","iopub.status.idle":"2024-04-08T07:21:34.715565Z","shell.execute_reply.started":"2024-04-08T07:21:33.763621Z","shell.execute_reply":"2024-04-08T07:21:34.714436Z"}}},{"cell_type":"code","source":"import os.path\nfrom os import path\n\n# Install the SDXL base model\ndef installSdxl(env):\n  installCmd = 'invokeai-model-install --add \"Lykon/dreamshaper-xl-1-0\" --root_dir /kaggle/temp/invokeai'\n  subprocess.run(installCmd, shell=True, env=env)\n  \nalreadyInstalled = True\nsdxlBaseSubfolderName = ''\nmodelsPath = '/kaggle/working/stablemodels/'\nsdxlBaseSubfolderName = '/dreamshaper-xl-1-0'\nworkSdxlMainFolder = modelsPath + 'sdxl/main'\nif not path.exists(workSdxlMainFolder):\n    os.makedirs(workSdxlMainFolder, exist_ok=True)\n    alreadyInstalled = False\n\ntempModelsSdxlFolder = '/kaggle/temp/invokeai/models/sdxl/'\ntempSdxlMainFolder = tempModelsSdxlFolder + 'main'\n\nsubprocess.run('rm -rf ' + tempModelsSdxlFolder, shell=True, env=env)\nif path.exists(tempModelsSdxlFolder):\n    subprocess.run('rmdir ' + tempModelsSdxlFolder, shell=True, env=env)\n\nif not alreadyInstalled:\n    if not path.exists(tempModelsSdxlFolder):\n      os.makedirs(tempModelsSdxlFolder, exist_ok=True)\n    subprocess.run('ln -s '+workSdxlMainFolder+' '+tempModelsSdxlFolder, shell=True, env=env)\n    installSdxl(env)\nelse:\n    if not path.exists(tempSdxlMainFolder):\n      os.makedirs(tempSdxlMainFolder, exist_ok=True)\n    subprocess.run('ln -s '+workSdxlMainFolder + sdxlBaseSubfolderName+' '+ tempSdxlMainFolder, shell=True, env=env)\n    updateModelsYaml = True\n    with open('/kaggle/temp/invokeai/configs/models.yaml') as f:\n      if 'dreamshaper-xl-1-0' in f.read():\n        updateModelsYaml = False\n    if updateModelsYaml:\n      with open('/kaggle/temp/invokeai/configs/models.yaml', 'a') as file:\n        lines = [\n          'sdxl/main/dreamshaper-xl-1-0:\\n',\n          '  path: sdxl/main/dreamshaper-xl-1-0\\n',\n          '  description: Dreamshaper XL (12 GB)\\n',\n          '  variant: normal\\n',\n          '  format: diffusers\\n'\n        ]\n        file.writelines(lines)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start Invokeai","metadata":{}},{"cell_type":"code","source":"#Option 2: Starting the Web UI with RemoteMoe\nport = 7860\n\n!mkdir  ~/.ssh/\n!touch  ~/.ssh/known_hosts\n!ssh-keyscan -t rsa remote.moe >> ~/.ssh/known_hosts\n!rm /root/.ssh/id_rsa\n!ssh-keygen -t rsa -b 4096 -f /root/.ssh/id_rsa -q -N \"\"\n!invokeai-web --root /kaggle/temp/invokeai/ & ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i ~/.ssh/id_rsa remote.moe","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}